

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/bigwrite.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="KafKa结构,API,消息可靠性的保证。">
  <meta name="author" content="Pb Cheng">
  <meta name="keywords" content="">
  
  <title>KafKa - 大橙</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/darcula.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>大橙</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/article/index0920.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="KafKa">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-09-20 16:01" pubdate>
        2021年9月20日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      5.7k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      67
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">KafKa</h1>
            
            <div class="markdown-body">
              <h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>基于发布订阅模式—&gt;消费者主动拉取，—–&gt;  要保持一个长轮询</p>
<p>​                               —-&gt;生产者推送—–&gt;消费速率不一致</p>
<p><img src="https://i.loli.net/2021/09/20/MxeF98qBbwEc2nu.png" srcset="/img/loading.gif" lazyload alt="image-20210920161052077"></p>
<p>Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上， 一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；（分区内有序，topic的全局无序）</p>
<p>消费者组内每个消费者负 责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所 有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>1.一个消费者组中的消费者不能消费同一个分区中的消息，消费者组中消费者的数量最好和主题的分区数相同。</p>
<p>2.保留消息的位置信息，保证消费者重启后可以恢复到上次的消费位置，保存在zk中（0.9之前存在zk中），0.9之后保存在kafka中，自动生成一个主题保存offset。</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight yml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yml"><span class="hljs-comment">#broker 的全局唯一编号，不能重复</span><br><span class="hljs-string">broker.id=0</span><br><span class="hljs-comment">#删除 topic 功能使能</span><br><span class="hljs-string">delete.topic.enable=true</span><br><span class="hljs-comment">#处理网络请求的线程数量</span><br><span class="hljs-string">num.network.threads=3</span><br><span class="hljs-comment">#用来处理磁盘 IO 的现成数量</span><br><span class="hljs-string">num.io.threads=8</span><br><span class="hljs-comment">#发送套接字的缓冲区大小</span><br><span class="hljs-string">socket.send.buffer.bytes=102400</span><br><span class="hljs-comment">#接收套接字的缓冲区大小</span><br><span class="hljs-string">socket.receive.buffer.bytes=102400</span><br><span class="hljs-comment">#请求套接字的缓冲区大小</span><br><span class="hljs-string">socket.request.max.bytes=104857600</span><br><span class="hljs-comment">#kafka 运行日志存放的路径</span><br><span class="hljs-string">log.dirs=/opt/module/kafka/logs</span><br><span class="hljs-comment">#topic 在当前 broker 上的分区个数</span><br><span class="hljs-string">num.partitions=1</span><br><span class="hljs-comment">#用来恢复和清理 data 下数据的线程数量</span><br><span class="hljs-string">num.recovery.threads.per.data.dir=1</span><br><span class="hljs-comment">#segment 文件保留的最长时间，超时将被删除</span><br><span class="hljs-string">log.retention.hours=168</span><br><span class="hljs-comment">#配置连接 Zookeeper 集群地址</span><br><span class="hljs-string">zookeeper.connect=localhost:2181</span><br><span class="hljs-number">5</span><span class="hljs-string">）配置环境变量</span><br> <span class="hljs-string">vi</span> <span class="hljs-string">/etc/profile</span><br><span class="hljs-comment">#KAFKA_HOME</span><br><span class="hljs-string">export</span> <span class="hljs-string">KAFKA_HOME=/opt/module/kafka</span><br><span class="hljs-string">export</span> <span class="hljs-string">PATH=$PATH:$KAFKA_HOME/bin</span><br>  <span class="hljs-string">source</span> <span class="hljs-string">/etc/profile</span><br></code></pre></div></td></tr></table></figure>

<p>远程访问配置</p>
<ul>
<li>把31行的注释去掉，listeners=PLAINTEXT://:9092</li>
<li>把36行的注释去掉，把advertised.listeners值改为PLAINTEXT://host_ip:9092</li>
</ul>
<p>bin/kafka-server-start.sh -daemon config/server.properties</p>
<h3 id="ZK启动报错"><a href="#ZK启动报错" class="headerlink" title="ZK启动报错"></a>ZK启动报错</h3><p>在<code>3.5.5版本</code>及以上，<code>Zookeeper</code> 提供了一个内嵌的<code>Jetty</code>容器来运行 <code>AdminServer</code>，默认占用的是 <code>8080</code>端口，<code>AdminServer</code> 主要是来查看 <code>Zookeeper</code> 的一些状态，如果机器上有其他程序（比如：<code>Tomcat</code>）占用了 <code>8080</code> 端口，也会导致<code> Starting zookeeper … FAILED TO START</code> 的问题。</p>
<p>可以通过以下几种方式去解决：</p>
<ol>
<li>如果不需要 <code>AdminServer</code> ，可以直接禁用：打开<code> zoo.cfg</code> 配置文件，直接添加以下语句即可。</li>
</ol>
<figure class="highlight yml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yml"><span class="hljs-comment"># 禁用 AdminServer 服务</span><br><span class="hljs-string">admin.enableServer=false</span><br></code></pre></div></td></tr></table></figure>

<ol start="2">
<li>如果想使用 <code>AdminServer</code> , 那么可以直接在 <code>zoo.cfg</code> 配置文件中修改端口号即可，比如让其绑定 <code>9000</code>。</li>
</ol>
<figure class="highlight yml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yml"><span class="hljs-comment"># admin port</span><br><span class="hljs-string">admin.serverPort=9000</span><br></code></pre></div></td></tr></table></figure>



<h3 id="kafka-文件系统"><a href="#kafka-文件系统" class="headerlink" title="kafka 文件系统"></a>kafka 文件系统</h3><p><img src="https://i.loli.net/2021/09/20/edZnzbxDSpKlIm3.png" srcset="/img/loading.gif" lazyload alt="image-20210920161150855"></p>
<p><img src="https://i.loli.net/2021/09/20/zNSlHZTsMPcG74a.png" srcset="/img/loading.gif" lazyload alt="image-20210920161220470"></p>
<p>生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位 效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment 对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名 规则为：topic 名称+分区序号。</p>
<p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元 数据指向对应数据文件中 message 的物理偏移地址。</p>
<p><img src="https://i.loli.net/2021/09/20/lV825p4G9ksfXmb.png" srcset="/img/loading.gif" lazyload alt="image-20210920161253572"></p>
<p>先二分查找 —&gt;查索引文件，找到消息在log文件中的偏移量，和消息大小，去log文件中读取消息。</p>
<h3 id="消息分区策略"><a href="#消息分区策略" class="headerlink" title="消息分区策略"></a>消息分区策略</h3><p>分区的好处：方便扩展，提高并发</p>
<ul>
<li><p>轮询</p>
</li>
<li><p>按消息的key值进行路由</p>
<p>我们需要将 producer 发送的数据封装成一个 ProducerRecord 对象。 </p>
<p>（1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值； </p>
<p>（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</p>
<p> （3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后 面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</p>
</li>
</ul>
<p><img src="https://i.loli.net/2021/09/20/9bjCegLqlTfOX3h.png" srcset="/img/loading.gif" lazyload alt="image-20210920161325940"></p>
<h3 id="数据可靠性的保证"><a href="#数据可靠性的保证" class="headerlink" title="数据可靠性的保证"></a>数据可靠性的保证</h3><p>为保证 producer 发送的数据，能可靠的发送到指定的 topic，topic 的每个 partition 收到 producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果 producer 收到 ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><img src="https://i.loli.net/2021/09/20/XQoSJvshVwMf6TC.png" srcset="/img/loading.gif" lazyload alt="image-20210920161353517"></p>
<p><strong>ISR</strong></p>
<p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集 合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower 长时间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由 <code> replica.lag.time.max.ms</code> 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。新版本采用同步时间选取follower 进入ISR，而不是消息数量差（默认消息数量差小于10000进入ISR，由于kafka是分batch写入，会造成ISR中的follower频繁变更），防止zk频繁变更配置。</p>
<h3 id="acks确认机制"><a href="#acks确认机制" class="headerlink" title="acks确认机制"></a>acks确认机制</h3><p>0：producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还 没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据； </p>
<p>1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据；</p>
<p>-1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower 全部落盘成功后才 返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会 造成数据重复。</p>
<h3 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h3><p><img src="https://i.loli.net/2021/09/20/94HxgYyN5ZuEmJS.png" srcset="/img/loading.gif" lazyload alt="image-20210920161447181"></p>
<p>高水位：最晚同步的follower中的数据。 </p>
<p>一个leader和其副本 中被消费者看到的数据  是该分片中的最高水位。保证在leader宕机时，消费的数据不会重复。</p>
<p>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。 </p>
<p>（1）follower 故障 ：follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了。 </p>
<p>（2）leader 故障 ：leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader 同步数据。</p>
<p> 注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复</p>
<p>数据重复：leader收到13-19宕机，生产者未收到ack，重新发送13-19，follower中13-15重复，</p>
<h3 id="kafka生产者"><a href="#kafka生产者" class="headerlink" title="kafka生产者"></a>kafka生产者</h3><p><img src="https://i.loli.net/2021/09/20/wjEeS7yd4VkDorT.png" srcset="/img/loading.gif" lazyload alt="image-20210920161513957"></p>
<figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//创建生产者</span><br><span class="hljs-keyword">private</span> Properties properties = <span class="hljs-keyword">new</span> Properties(); properties.put(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>,<span class="hljs-string">&quot;broker1:9092,broker2:9092&quot;</span>); properties.put(<span class="hljs-string">&quot;key.serializer&quot;</span>,<span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>); properties.put(<span class="hljs-string">&quot;value.serializer&quot;</span>,<span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>); properties = <span class="hljs-keyword">new</span> KafkaProducer&lt;String,String&gt;(properties);<br><span class="hljs-comment">//直接发送</span><br>ProducerRecord&lt;String,String&gt; record =<br>                <span class="hljs-keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="hljs-string">&quot;CustomerCountry&quot;</span>,<span class="hljs-string">&quot;West&quot;</span>,<span class="hljs-string">&quot;France&quot;</span>);<br><br>producer.send(record);<br><span class="hljs-comment">//同步发送</span><br><span class="hljs-comment">//种发送消息的方式较上面的发送方式有了改进，首先调用 send() 方法，然后再调用 get() 方法等待 Kafka 响应。如果服务器返回错误，get() 方法会抛出异常，如果没有发生错误，我们会得到 RecordMetadata 对象，可以用它来查看消息记录。</span><br><br>ProducerRecord&lt;String,String&gt; record =<br>                <span class="hljs-keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="hljs-string">&quot;CustomerCountry&quot;</span>,<span class="hljs-string">&quot;West&quot;</span>,<span class="hljs-string">&quot;France&quot;</span>);<br><br><span class="hljs-keyword">try</span>&#123;<br>  RecordMetadata recordMetadata = producer.send(record).get();<br>&#125;<span class="hljs-keyword">catch</span>(Exception e)&#123;<br>  e.printStackTrace()；<br>&#125;<br><span class="hljs-comment">//异步发送</span><br><span class="hljs-comment">//实现回调需要定义一个实现了org.apache.kafka.clients.producer.Callback的类，这个接口只有一个 onCompletion方法。</span><br><span class="hljs-comment">//如果 kafka 返回一个错误，onCompletion 方法会抛出一个非空(non null)异常，这里我们只是简单的把它打印出来，如果是生产环境需要更详细的处理，然后在 send() 方法发送的时候传递一个 Callback 回调的对象。</span><br>ProducerRecord&lt;String, String&gt; producerRecord = <span class="hljs-keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="hljs-string">&quot;CustomerCountry&quot;</span>, <span class="hljs-string">&quot;Huston&quot;</span>, <span class="hljs-string">&quot;America&quot;</span>);<br>        producer.send(producerRecord,<span class="hljs-keyword">new</span> DemoProducerCallBack());<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DemoProducerCallBack</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Callback</span> </span>&#123;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onCompletion</span><span class="hljs-params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span>(exception != <span class="hljs-keyword">null</span>)&#123;<br>      exception.printStackTrace();;<br>    &#125;<br>  &#125;<br>&#125;<br><br></code></pre></div></td></tr></table></figure>

<h3 id="幂等性发送"><a href="#幂等性发送" class="headerlink" title="幂等性发送"></a>幂等性发送</h3><p> 引入了Producer ID（PID）和Sequence Number实现Producer的幂等语义。</p>
<ul>
<li>Producer ID：每个新的Producer在初始化的时候会被分配一个唯一的PID</li>
<li>Sequence Number：对于每个PID，该Producer发送数据的每个&lt;Topic, Partition&gt;都对应一个从0开始单调递增的Sequence Number。</li>
</ul>
<p>Broker端也会为每个&lt;PID, Topic, Partition&gt;维护一个序号，并且每次Commit一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比Broker维护的序号（即最后一次Commit的消息的序号）大一，则Broker会接受它，否则将其丢弃：</p>
<ul>
<li>如果消息序号比Broker维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时Broker拒绝该消息，Producer抛出InvalidSequenceNumber</li>
<li>如果消息序号小于等于Broker维护的序号，说明该消息已被保存，即为重复消息，Broker直接丢弃该消息，Producer抛出DuplicateSequenceNumber</li>
</ul>
<p>这种机制很好的解决了数据重复和数据乱序的问题。</p>
<h3 id="Exactly-Once"><a href="#Exactly-Once" class="headerlink" title="Exactly Once"></a>Exactly Once</h3><p>将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。</p>
<p>相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被 发送一次，即 At Most Once 语义。</p>
<p> At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once 可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说 交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。</p>
<p>在 0.11 版 本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局 去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。 0.11 版本的 Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指 Producer 不论 向 Server 发送多少次重复数据，Server 端都只会持久化一条。幂等性结合 At Least Once 语 义，就构成了 Kafka 的 Exactly Once 语义。</p>
<p>即： At Least Once + 幂等性 = Exactly Once 要启用幂等性，只需要将 Producer 的参数中 <strong>enable.idompotence</strong> 设置为 true 即可。Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在 初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而 Broker 端会对做缓存，当具有相同主键的消息提交时，Broker 只 会持久化一条。 但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证跨 分区跨会话的 Exactly Once。</strong></p>
<h3 id="kafka事务"><a href="#kafka事务" class="headerlink" title="kafka事务"></a>kafka事务</h3><p>多个操作要么全部成功要么全部失败。Kafka事务的本质是，将一组写操作（如果有）对应的消息与一组读操作（如果有）对应的Offset的更新进行同样的标记（即Transaction Marker）来实现事务中涉及的所有读写操作同时对外可见或同时对外不可见。</p>
<p>事务可以保证 Kafka 在 Exactly Once 语义的基 础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<p><strong>producer 事务</strong></p>
<p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID（由客户端指定，重启后Transaction ID不变），并将 Producer 获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。 为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就 是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于 事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h3 id="kafka消费者"><a href="#kafka消费者" class="headerlink" title="kafka消费者"></a>kafka消费者</h3><p>consumer 采用 pull（拉）模式从 broker 中读取数据。 </p>
<p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。 它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。</p>
<p>而 pull 模式则可以根据 consumer 的消费能力以适 当的速率消费消息。 pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直返回空数 据。针对这一点，Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有 数据可供消费，consumer 会等待一段时间之后再返回，这段时长即为 timeout。</p>
<h3 id="消息分区"><a href="#消息分区" class="headerlink" title="消息分区"></a>消息分区</h3><p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及 到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。 Kafka 有两种分配策略，一是 RoundRobin，一是 Range –默认。</p>
<p><strong>range策略</strong>主要是基于范围的思想。</p>
<p>它将单个topic的所有分区按照顺序排列，然后把这些分区划分成固定大小的分区段并依次分配给每个consumer。</p>
<p><strong>round-robin策略</strong>则会把所有topic的所有分区顺序摆开，然后轮询式地分配给各个consumer组。</p>
<h3 id="消费者重平衡"><a href="#消费者重平衡" class="headerlink" title="消费者重平衡"></a>消费者重平衡</h3><p>重平衡非常重要，它为消费者群组带来了<code>高可用性</code> 和 <code>伸缩性</code>，我们可以放心的添加消费者或移除消费者，不过在正常情况下我们并不希望发生这样的行为。在重平衡期间，消费者无法读取消息，造成整个消费者组在重平衡的期间都不可用。另外，当分区被重新分配给另一个消费者时，消息当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。</p>
<p>消费者通过向<code>组织协调者</code>（Kafka Broker）发送心跳来维护自己是消费者组的一员并确认其拥有的分区。对于不同不的消费群体来说，其组织协调者可以是不同的。只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心跳。</p>
<p>如果过了一段时间 Kafka 停止发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡。如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡。在这段时间里，<strong>死亡的消费者将不处理任何消息</strong>。在清理消费者时，消费者将通知协调者它要离开群组，组织协调者会触发一次重平衡，尽量降低处理停顿。</p>
<p>在重平衡期间，消费者组中的消费者实例都会停止消费，等待重平衡的完成。而且重平衡这个过程很慢</p>
<h3 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h3><p>消费者在每次调用<code>poll()</code> 方法进行定时轮询的时候，会返回由生产者写入 Kafka 但是还没有被消费者消费的记录，因此我们可以追踪到哪些记录是被群组里的哪个消费者读取的。消费者可以使用 Kafka 来追踪消息在分区中的位置（偏移量）</p>
<p>消费者会向一个叫做 <code>_consumer_offset</code> 的特殊主题中发送消息，这个主题会保存每次所发送消息中的分区偏移量，这个主题的主要作用就是消费者触发重平衡后记录偏移使用的，消费者每次向这个主题发送消息，正常情况下不触发重平衡，这个主题是不起作用的，当触发重平衡后，消费者停止工作，每个消费者可能会分到对应的分区，这个主题就是让消费者能够继续处理消息所设置的。</p>
<p>如果提交的偏移量小于客户端最后一次处理的偏移量，那么位于两个偏移量之间的消息就会被重复处理</p>
<p><img src="https://i.loli.net/2021/09/20/Zo9rkBVltFMq6Rm.png" srcset="/img/loading.gif" lazyload alt="image-20210920161706917"></p>
<p>如果提交的偏移量大于最后一次消费时的偏移量，那么处于两个偏移量中间的消息将会丢失</p>
<p><img src="https://i.loli.net/2021/09/20/JETyCcqQxkAd8YO.png" srcset="/img/loading.gif" lazyload alt="image-20210920161622150"></p>
<h3 id="Kafka-API"><a href="#Kafka-API" class="headerlink" title="Kafka API"></a>Kafka API</h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">./bin/kafka-server-start.sh -daemon config/server.properties <br>./kafka-topics.sh --create --zookeeper localhost:2181 --topic first --partitions 1 --replication-factor 1<br><br>./kafka-topics.sh --list --zookeeper localhost:2181<br><br>./kafka-topics.sh --describe --zookeeper localhost:2181 --topic first<br><br>./kafka-topics.sh --delete --zookeeper localhost:2181 --topic first<br><br>./kafka-console-producer.sh --topic first --broker-list `host-ip`:9092<br><br>./kafka-console-consumer.sh --topic first --bootstrap-server `host-ip`:9092<br></code></pre></div></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/09/20/YoUT4A6ZXqQ2mar.png" srcset="/img/loading.gif" lazyload alt="image-20210920161556254"></p>
<ul>
<li>kafkaproducer</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">kafkaproducer</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>        Properties props = <span class="hljs-keyword">new</span> Properties();<br>        props.put(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;8.140.168.124:9092&quot;</span>);<span class="hljs-comment">//kafka 集群，broker-list</span><br>        props.put(<span class="hljs-string">&quot;acks&quot;</span>, <span class="hljs-string">&quot;all&quot;</span>);<br>        props.put(<span class="hljs-string">&quot;retries&quot;</span>, <span class="hljs-number">1</span>);<span class="hljs-comment">//重试次数</span><br>        props.put(<span class="hljs-string">&quot;batch.size&quot;</span>, <span class="hljs-number">16384</span>);<span class="hljs-comment">//批次大小</span><br>        props.put(<span class="hljs-string">&quot;linger.ms&quot;</span>, <span class="hljs-number">1</span>);<span class="hljs-comment">//等待时间</span><br>        props.put(<span class="hljs-string">&quot;buffer.memory&quot;</span>, <span class="hljs-number">33554432</span>);<span class="hljs-comment">//RecordAccumulator 缓冲区大小</span><br>        props.put(<span class="hljs-string">&quot;key.serializer&quot;</span>,<br>                <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>        props.put(<span class="hljs-string">&quot;value.serializer&quot;</span>,<br>                <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>        Producer&lt;String, String&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) &#123;<br>            producer.send(<span class="hljs-keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="hljs-string">&quot;test-1&quot;</span>,<br>                    Integer.toString(i), Integer.toString(i)), <span class="hljs-keyword">new</span> Callback() &#123;<br>                <span class="hljs-comment">//回调函数，该方法会在 Producer 收到 ack 时调用，为异步调用</span><br>                <span class="hljs-meta">@Override</span><br>                <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onCompletion</span><span class="hljs-params">(RecordMetadata metadata,</span></span><br><span class="hljs-params"><span class="hljs-function">                                         Exception exception)</span> </span>&#123;<br>                    <span class="hljs-keyword">if</span> (exception == <span class="hljs-keyword">null</span>) &#123;<br>                        System.out.println(<span class="hljs-string">&quot;success-&gt;&quot;</span> + metadata.offset());<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        exception.printStackTrace();<br>                    &#125;<br>                &#125;<br>            &#125;);<br>        &#125;<br>        producer.close();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>

<ul>
<li>kafkaconsumer</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">kafkaconsumer</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>            <span class="hljs-comment">//创建kafka消费者配置信息</span><br>            Properties properties = <span class="hljs-keyword">new</span> Properties();<br>            <span class="hljs-comment">//连接Kafka</span><br>            properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">&quot;8.140.168.124:9092&quot;</span>);<br>            <span class="hljs-comment">//自动提交</span><br>            properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="hljs-keyword">false</span>);<br>            <span class="hljs-comment">//自动提交延迟</span><br>            properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="hljs-string">&quot;1000&quot;</span>);<br>            <span class="hljs-comment">//消费者组</span><br>            properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="hljs-string">&quot;group1&quot;</span>);<br>            <span class="hljs-comment">//key,value反序列化</span><br>            properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);<br>            properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);<br><br>            KafkaConsumer&lt;String, String&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(properties);<br>            <span class="hljs-comment">//订阅主题，可同时订阅多个</span><br>            consumer.subscribe(Collections.singletonList(<span class="hljs-string">&quot;test-1&quot;</span>));<br>            <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>                ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(<span class="hljs-number">100</span>);<br>                <span class="hljs-keyword">for</span> (ConsumerRecord record : consumerRecords) &#123;<br>                    System.out.println(<span class="hljs-string">&quot;key: &quot;</span> + record.key() + <span class="hljs-string">&quot;  &quot;</span> + <span class="hljs-string">&quot;value: &quot;</span> + record.value());<br>                &#125;<br>                consumer.commitAsync(<span class="hljs-keyword">new</span> OffsetCommitCallback() &#123;<br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onComplete</span><span class="hljs-params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;<br>                        <span class="hljs-keyword">if</span> (exception != <span class="hljs-keyword">null</span>) &#123;<br>                            System.err.println(<span class="hljs-string">&quot;Commit failed for&quot;</span> + offsets);<br>                        &#125;<br>                    &#125;<br>                &#125;);<br>            &#125;<br>        &#125;<br>    &#125;<br></code></pre></div></td></tr></table></figure>

<p>异步提交offset，可能会造成：数据读取到，处理完后，offset还未提交，消费者宕机重启会重新消费。</p>
<p>可以自定义offset，将提交和业务逻辑做成一个事务。</p>
<h3 id="消息的乱序重复丢失积压问题"><a href="#消息的乱序重复丢失积压问题" class="headerlink" title="消息的乱序重复丢失积压问题"></a>消息的乱序重复丢失积压问题</h3><p>乱序：kafka只支持分区有序，要开启kafka的幂等性配置，给消息生成seq（序列号），当kafka收到的消息无序时会被丢弃，对于需要依靠消息有序的逻辑，可以制定key值将消息路由到同一个分区中。—–幂等性发送</p>
<p>重复：</p>
<p>无论是同步提交还是异步提交 offset，都有可能会造成数据的漏消费或者重复消费。先 提交 offset 后消费，有可能造成数据的漏消费；而先消费后提交 offset，有可能会造成数据 的重复消费。</p>
<p>kafka开启幂等性发送，消费者端消费时异步提交offset，消费成功才提交，防止重复消费。</p>
<p>丢失：生产者开启回调，未收到ack时重新发送。</p>
<p>​           kafka集群ack配置为-1（all），所有的ISR副本收到消息才会恢复ack。</p>
<p>​           消费者：未消费完服务宕机，而offset已经发送，重启会消费下一条，可以开启异步提交offset，消费完成才提交offset。</p>
<p>积压：kafka主题增加分区数和消费者数量，增加并行处理能力。</p>
<p>​           消费者增加批次拉取的消息数量。</p>
<h3 id="效率高的原因"><a href="#效率高的原因" class="headerlink" title="效率高的原因"></a>效率高的原因</h3><ul>
<li>顺序读写</li>
</ul>
<p>kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能</p>
<p>顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p>
<ul>
<li>批处理</li>
</ul>
<p>kafka允许进行批量发送消息，producter发送消息的时候，可以将消息缓存在本地,等到了固定条件发送到kafka</p>
<p>1）等消息条数到固定条数</p>
<p>2）一段时间发送一次</p>
<ul>
<li>分区机制</li>
</ul>
<p>kafka中的topic中的内容可以被分为多分partition存在,每个partition又分为多个段segment,所以每次操作都是针对一小部分做操作，很轻便，并且增加<code>并行操作</code>的能力</p>
<ul>
<li>零拷贝（MMap，简历文件缓冲区和用户缓冲区的内存映射，直接操作内核态的文件缓冲区）（SendFile，直接在内核态的文件缓冲区和socket缓冲区传递文件描述符，网卡的支持DMA，全称叫Direct Memory Access，一种可让某些硬件子系统去直接访问系统主内存，而不用依赖CPU的计算机系统的功能。跳过CPU，直接访问主内存。）</li>
</ul>
<p>跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”</p>
<ul>
<li>数据压缩</li>
</ul>
<p>Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩 压缩的好处就是减少传输的数据量，减轻对网络传输的压力。</p>
<p><code>批量发送</code>和<code>数据压缩</code>一起使用,单条做数据压缩的话，效果不明显</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/KafKa/">KafKa</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/">中间件</a>
                    
                      <a class="hover-with-bg" href="/tags/KafKa/">KafKa</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/05/ElasticSearch/">
                        <span class="hidden-mobile">ElasticSearch</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
    
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
